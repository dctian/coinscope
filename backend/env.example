# VLM Configuration
# Choose your VLM provider by setting the model name:
#
# Direct Gemini SDK (recommended for accuracy):
#   - gemini-2.0-flash (fast, good accuracy)
#   - gemini-1.5-pro (best accuracy)
#   - gemini-1.5-flash (balanced)
#
# Via LiteLLM (use gemini/ prefix):
#   - gemini/gemini-1.5-pro
#   - gpt-4-vision-preview (OpenAI)
#   - claude-3-opus-20240229 (Anthropic)
#
VLM_MODEL=gemini-2.0-flash

# API Keys (provide the key for your chosen provider)
OPENAI_API_KEY=sk-your-openai-key
GEMINI_API_KEY=your-gemini-key
ANTHROPIC_API_KEY=your-anthropic-key

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=true

